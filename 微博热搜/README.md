# 微博热搜

本程序可以以一定时间间隔（如每隔一小时）爬取新浪微博**热搜榜**，**话题榜**，**要闻榜**（如[热搜榜](https://weibo.cn/u/1223178222)、[话题榜](https://weibo.cn/u/1669879400)、[要闻榜](https://weibo.cn/u/1729370543)）的数据，并将结果信息写入**.md文件**,**.csv文件**,**redis数据库**。写入信息几乎包括榜单的所有数据。包括**榜单**和**微博信息**两大类。~~因为内容太多，这里不再赘述，详细内容见[获取到的字段](#获取到的字段)。如果只需要用户信息，可以通过设置实现只爬取微博用户信息的功能。本程序需设置cookie来获取微博访问权限，后面会讲解[如何获取cookie](#如何获取cookie)。如果不想设置cookie，可以使用[免cookie版](https://github.com/dataabc/weibo-crawler)，二者功能类似。~~

爬取结果可写入文件和数据库，具体的写入文件类型如下：

- **md文件**（默认）
- **csv文件**（默认）
- **Redis数据库**（默认）
- **json文件**（可选）
- ~~**MySQL数据库**（可选）~~
- ~~**MongoDB数据库**（可选）~~
- ~~**SQLite数据库**（可选）~~
- ~~**txt文件**（可选）~~

## ~~内容列表~~



- 

## ~~获取到的字段~~



### ~~用户信息~~

- 

### ~~微博信息~~

- 

## ~~示例~~

~~如果想要知道程序的具体运行结果，可以查看[示例文档](https://github.com/dataabc/weiboSpider/blob/master/docs/example.md)，该文档介绍了爬取[迪丽热巴微博](https://weibo.cn/u/1669879400)的例子，并附有部分结果文件截图。~~

## 运行环境

- 开发语言：python3
- 系统： Windows/

## ~~使用说明~~



1. 